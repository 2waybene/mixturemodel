{
index =  which(peaks < 2) [length(which(peaks < 2))]
}
third_round
index
if (index >=1)
{
secondDT.1 <- getPopWIndex (secondDT.cleaned, index)
#plot(density(secondDT.1))
#plot(density(secondDT.1 + peaks[index]))
secondDT.2.cleaned <- cleanFirstPop(peaks[index],  secondDT.1, secondDT.cleaned)
third_round = 1
#str(secondDT.2.cleaned)
#plot(density(secondDT.2.cleaned))
#stats (secondDT.2.cleaned)
}else{
secondDT.2.cleaned <- secondDT.cleaned
}
secondDT.2.cleaned
library(ks)
set.seed(1)
par(mfrow=c(2,1))
x<-rlnorm(100)
hist(x, col="red", freq=F)
lines(density(x))
y <- rkde(fhat=kde(x=x, h=hpi(x)), n=100, positive=TRUE)
hist(y, col="green", freq=F)
#	simulating DNA D.I. values
# Need to source ~/myGit/mixturemodel/Scripts/simDt_functions.R
#	normal population
library(Rlab)
##  OS specific directories:
mac.os  <- "/Users/li11/"
linux   <- "~/"
windows <- "X:/"
root <- mac.os
source (paste (root, "/myGit/mixturemodel/Scripts/simDt_functions.R", sep=""))
source (paste (root, "/myGit/mixturemodel/Scripts/simDt_functions.R", sep=""))
mean.norm <- c()
for (i in 1:20)
{
mean.norm[i] <- runif (1, 0.9,1.2)
}
mean.normalP <- mean.norm[sample(1:20,1)]
#	mitotic population
mean.mitotic <- c()
for (i in 1:20)
{
mean.mitotic[i] <- runif (1, 1.7,2.2)
}
mean.mitoticP <- mean.mitotic[sample(1:20,1)]
#	aneuploidy  population
mean.aneu <- 3.3
st.aneu <-3.5
n = 40
sample.aneu <- rnorm(n, mean = mean.aneu, sd = st.aneu)
sample.aneuP <- sample.aneu[sample.aneu >=0]
plot(density(sample.aneuP))
mean.aneuP <- mean(sample.aneuP)
sigmaA <- sd(sample.aneuP)
#  simulating DNA D.I. values
# Need to source ~/myGit/mixturemodel/Scripts/simDt_functions.R
#	normal population
library(Rlab)
##  OS specific directories:
mac.os  <- "/Users/li11/"
linux   <- "~/"
windows <- "X:/"
##=============================================
##  Read in data
##=============================================
#root <- windows
root <- mac.os
dt.dir <- paste (root, "/myGit/mixturemodel/cleanedData/OSCC", sep="")
files <- list.files (pattern=".rda")
files
files <- list.files (path = dt.dir, pattern=".rda")
files
i=1
load(paste(dt.dir, files[i], sep=""))
files[i]
dt.dir <- paste (root, "/myGit/mixturemodel/cleanedData/OSCC/", sep="")
files <- list.files (path = dt.dir, pattern=".rda")
files
aneuMax = 0;
aneuMin = 0;
i=1
load(paste(dt.dir, files[i], sep=""))
str()
ls()
str(cleanedSample)
str(cleanedSample$Aneuleft)
str(cleanedSample$AneuLeft)
max(cleanedSample$AneuLeft)
aneuMax = 0;
aneuMin = 2.3;
for (i in 1:length(files))
{
load(paste(dt.dir, files[i], sep=""))
if (aneuMax < max(cleanedSample$AneuLeft))
{
aneuMax = max(cleanedSample$AneuLeft))
}
}
i=1
load(paste(dt.dir, files[i], sep=""))
for (i in 1:length(files))
{
load(paste(dt.dir, files[i], sep=""))
if (aneuMax < max(cleanedSample$AneuLeft))
{
aneuMax = max(cleanedSample$AneuLeft)
}
}
for (i in 1:length(files))
{
load(paste(dt.dir, files[i], sep=""))
if (cleanedSample$AneuLeft) != "")
{
if (aneuMax < max(cleanedSample$AneuLeft))
{
aneuMax = max(cleanedSample$AneuLeft)
}
}
}
for (i in 1:length(files))
{
load(paste(dt.dir, files[i], sep=""))
if (cleanedSample$AneuLeft != "")
{
if (aneuMax < max(cleanedSample$AneuLeft))
{
aneuMax = max(cleanedSample$AneuLeft)
}
}
}
i
(cleanedSample$AneuLeft != "")
cleanedSample$AneuLeft
cleanedSample
cleanedSample$AneuLeft
length(cleanedSample$AneuLeft)
(length(cleanedSample$AneuLeft) != 0)
for (i in 1:length(files))
{
load(paste(dt.dir, files[i], sep=""))
if (length(cleanedSample$AneuLeft) != 0)
{
if (aneuMax < max(cleanedSample$AneuLeft))
{
aneuMax = max(cleanedSample$AneuLeft)
}
}
}
aneuMax
?do.call
do.call("complex", list(imag = 1:3))
library(golubEsets)
library(pvca)
data(Golub_Merge)
pct_threshold <- 0.6
batch.factors <- c("ALL.AML", "BM.PB", "Source")
pvcaObj <- pvcaBatchAssess (Golub_Merge, batch.factors, pct_threshold)
bp <- barplot(pvcaObj$dat,  xlab = "Effects",
ylab = "Weighted average proportion variance",
ylim= c(0,1.1),col = c("blue"), las=2,
main="PVCA estimation bar chart")
axis(1, at = bp, labels = pvcaObj$label, xlab = "Effects", cex.axis = 0.5, las=2)
values = pvcaObj$dat
new_values = round(values , 3)
text(bp,pvcaObj$dat,labels = new_values, pos=3, cex = 0.8)
license()
demo()
library(AppliedPredictiveModeling)
transparentTheme(trans = 0.4)
plotSubset <- data.frame(scale(mdrrDescr[, c("nC", "X4v")]))
xyplot(nC ~ X4v,
data = plotSubset,
groups = mdrrClass,
auto.key = list(columns = 2))
plot(1:5)
5908*12
#===============================================
##	Set up os paths
##==============================================
mac.os  <- "/Users/li11/"
linux   <- "~/"
windows <- "X:/"
root <- mac.os
library(caret)
#===============================================
##	Set up os paths
##==============================================
mac.os  <- "/Users/li11/"
linux   <- "~/"
windows <- "X:/"
root <- mac.os
library(caret)
##===================================
## set up working directory
## and getting the dataset
##===================================
setwd(paste (root, "/myGit/mixturemodel/reconData/para2/", sep=""))
#data <- read.table("recon_3classes_para3.txt", header=TRUE, sep = "\t")
#data <- read.table("recon_3classes_para1.txt", header=TRUE, sep = "\t")
data <- read.table("recon_3classes_para2.txt", header=TRUE, sep = "\t")
##	data cleaning
var0 <- unlist(lapply(data, function(x) 0 == var(if (is.factor(x)) as.integer(x) else x)))
dataN0 <- data[,-which(var0)]
# drop the first column of ID?
dataN0[,1] <- NULL
##	Retain data ONLY with two classes
data.2.classes <- dataN0[-which (dataN0$label == "k"),]
data.k <- dataN0[which (dataN0$label == "k"),]
dim(data.2.classes)
labels <- as.vector(data.2.classes$label)
data.2.classes <- data.2.classes[,-16]
data.2.classes <- cbind (data.2.classes, label=labels)
table(factor(data.2.classes$label))
file2classes  <- data.2.classes
file.olk <- data.k
## create data partition
inTrainingSet <- createDataPartition(file2classes$label, p=.7, list=FALSE)
labelTrain <- file2classes[ inTrainingSet,]
labelTest <- file2classes[-inTrainingSet,]
nrow(labelTrain)
nrow(labelTest)
##=======================
##	rpart
##=======================
library(rpart)
library(partykit)
rpartFull <- rpart(label ~ ., data = labelTrain)
rpartFull
library(partykit)
rpartFulla <- as.party(rpartFull)
plot(rpartFulla)
rpartPred <- predict(rpartFull, labelTest, type = "class")
confusionMatrix(rpartPred, labelTest$label)   # requires 2 factor vectors
##################################################################
cvCtrl <- trainControl(method = "repeatedcv", repeats = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
cvCtrl.2 <- trainControl(method = "LOOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE)
set.seed(1)
rpartTune <- train(label ~ ., data = labelTrain,
method = "rpart",
tuneLength = 10,
metric = "ROC",
trControl = cvCtrl)
rpartTune
trellis.par.set(caretTheme())
plot(rpartTune, scales = list(x = list(log = 10)))
ggplot(rpartTune) +scale_x_log10()
###############################################################
## Slide 78: Test Set Results
rpartPred2 <- predict(rpartTune, labelTest)
confusionMatrix(rpartPred2, labelTest$label)
###############################################################
## Slide 79: Predicting Class Probabilities
rpartProbs <- predict(rpartTune, labelTest, type = "prob")
head(rpartProbs)
##====================================
##	SVM Example
##====================================
set.seed(1)
svmTune <- train(label ~ .,
data = labelTrain,
method = "svmRadial",
# The default grid of cost parameters go from 2^-2,
# 0.5 to 1,
# We'll fit 9 values in that sequence via the tuneLength
# argument.
tuneLength = 9,
preProc = c("center", "scale"),
metric = "ROC",
trControl = cvCtrl)
library(caret)
##===================================
## set up working directory
## and getting the dataset
##===================================
setwd(paste (root, "/myGit/mixturemodel/reconData/para2/", sep=""))
#data <- read.table("recon_3classes_para3.txt", header=TRUE, sep = "\t")
#data <- read.table("recon_3classes_para1.txt", header=TRUE, sep = "\t")
data <- read.table("recon_3classes_para2.txt", header=TRUE, sep = "\t")
##	data cleaning
var0 <- unlist(lapply(data, function(x) 0 == var(if (is.factor(x)) as.integer(x) else x)))
dataN0 <- data[,-which(var0)]
# drop the first column of ID?
dataN0[,1] <- NULL
##	Retain data ONLY with two classes
data.2.classes <- dataN0[-which (dataN0$label == "k"),]
data.k <- dataN0[which (dataN0$label == "k"),]
dim(data.2.classes)
labels <- as.vector(data.2.classes$label)
data.2.classes <- data.2.classes[,-16]
data.2.classes <- cbind (data.2.classes, label=labels)
table(factor(data.2.classes$label))
file2classes  <- data.2.classes
file.olk <- data.k
## create data partition
inTrainingSet <- createDataPartition(file2classes$label, p=.7, list=FALSE)
labelTrain <- file2classes[ inTrainingSet,]
labelTest <- file2classes[-inTrainingSet,]
nrow(labelTrain)
nrow(labelTest)
##=======================
##	rpart
##=======================
library(rpart)
library(partykit)
rpartFull <- rpart(label ~ ., data = labelTrain)
rpartFull
library(partykit)
rpartFulla <- as.party(rpartFull)
plot(rpartFulla)
rpartPred <- predict(rpartFull, labelTest, type = "class")
confusionMatrix(rpartPred, labelTest$label)   # requires 2 factor vectors
##################################################################
cvCtrl <- trainControl(method = "repeatedcv", repeats = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
cvCtrl.2 <- trainControl(method = "LOOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE)
set.seed(1)
rpartTune <- train(label ~ ., data = labelTrain,
method = "rpart",
tuneLength = 10,
metric = "ROC",
trControl = cvCtrl)
rpartTune
trellis.par.set(caretTheme())
plot(rpartTune, scales = list(x = list(log = 10)))
ggplot(rpartTune) +scale_x_log10()
###############################################################
## Slide 78: Test Set Results
rpartPred2 <- predict(rpartTune, labelTest)
confusionMatrix(rpartPred2, labelTest$label)
###############################################################
## Slide 79: Predicting Class Probabilities
rpartProbs <- predict(rpartTune, labelTest, type = "prob")
head(rpartProbs)
##====================================
##	SVM Example
##====================================
set.seed(1)
svmTune <- train(label ~ .,
data = labelTrain,
method = "svmRadial",
# The default grid of cost parameters go from 2^-2,
# 0.5 to 1,
# We'll fit 9 values in that sequence via the tuneLength
# argument.
tuneLength = 9,
preProc = c("center", "scale"),
metric = "ROC",
trControl = cvCtrl)
root
data
dim(data.2.classes)
nrow(labelTrain)
nrow(labelTest)
##=======================
##	rpart
##=======================
library(rpart)
library(partykit)
rpartFull <- rpart(label ~ ., data = labelTrain)
rpartFull
library(partykit)
rpartFulla <- as.party(rpartFull)
plot(rpartFulla)
rpartPred <- predict(rpartFull, labelTest, type = "class")
confusionMatrix(rpartPred, labelTest$label)   # requires 2 factor vectors
##################################################################
cvCtrl <- trainControl(method = "repeatedcv", repeats = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
cvCtrl.2 <- trainControl(method = "LOOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE)
set.seed(1)
rpartTune <- train(label ~ ., data = labelTrain,
method = "rpart",
tuneLength = 10,
metric = "ROC",
trControl = cvCtrl)
rpartTune
trellis.par.set(caretTheme())
plot(rpartTune, scales = list(x = list(log = 10)))
ggplot(rpartTune) +scale_x_log10()
###############################################################
## Slide 78: Test Set Results
rpartPred2 <- predict(rpartTune, labelTest)
confusionMatrix(rpartPred2, labelTest$label)
###############################################################
## Slide 79: Predicting Class Probabilities
rpartProbs <- predict(rpartTune, labelTest, type = "prob")
head(rpartProbs)
##====================================
##	SVM Example
##====================================
set.seed(1)
svmTune <- train(label ~ .,
data = labelTrain,
method = "svmRadial",
# The default grid of cost parameters go from 2^-2,
# 0.5 to 1,
# We'll fit 9 values in that sequence via the tuneLength
# argument.
tuneLength = 9,
preProc = c("center", "scale"),
metric = "ROC",
trControl = cvCtrl)
svmPred <- predict(svmTune, labelTest)
confusionMatrix(svmPred, labelTest$label)
##=============================
##	Test on olk sample
##=============================
dim(file.olk)
svmPred.k.prob  <- predict(svmTune, file.olk, type = "prob")
den.c <- density(svmPred.k.prob$c)
den.n <- density(svmPred.k.prob$n)
plot( den.c)
lines( den.n, col = "red")
rep ("c", length(label.c.as.c))
rep ("n", length(label.n.as.c))
rep ("k", length(label.k.as.c))
predicted.c <- list (label = as.vector(c(rep ("n", length(label.n.as.c)), rep ("k", length(label.k.as.c)), rep ("c", length(label.c.as.c)))),
prob = as.vector(c( svmPredProb$c[labelTest$label=="n"], svmPred.k.prob$c, svmPredProb$c[labelTest$label=="c"])))
str(predicted.c)
boxplot(prob ~ label, data = as.data.frame(predicted.c), main = "Samples (by label) predicted as OSCC", ylab = "Probability", outpch = NA)
stripchart(prob ~ label, data = as.data.frame(predicted.c),
vertical = TRUE, method = "jitter",
pch = 21, col = "maroon", bg = "bisque",
add = TRUE)
mtext ("Prediction probability")
##====================================
##	SVM Example
##====================================
set.seed(1)
svmTune <- train(label ~ .,
data = labelTrain,
method = "svmRadial",
# The default grid of cost parameters go from 2^-2,
# 0.5 to 1,
# We'll fit 9 values in that sequence via the tuneLength
# argument.
tuneLength = 9,
preProc = c("center", "scale"),
metric = "ROC",
trControl = cvCtrl.2)
svmPred <- predict(svmTune, labelTest)
confusionMatrix(svmPred, labelTest$label)
svmPredProb <- predict(svmTune, labelTest , type = "prob")
boxplot(svmPredProb)
#points(svmPredProb)
str(svmPredProb)
label.c.as.c <- svmPredProb$c[labelTest$label=="c"]
label.n.as.c <- svmPredProb$c[labelTest$label=="n"]
svmPredProb$c =="c"
boxplot(svmPredProb, outpch = NA)
stripchart(svmPredProb,
vertical = TRUE, method = "jitter",
pch = 21, col = "maroon", bg = "bisque",
add = TRUE)
rep ("c", length(label.c.as.c))
rep ("n", length(label.n.as.c))
rep ("k", length(label.k.as.c))
predicted.c <- list (label = as.vector(c(rep ("n", length(label.n.as.c)), rep ("k", length(label.k.as.c)), rep ("c", length(label.c.as.c)))),
prob = as.vector(c( svmPredProb$c[labelTest$label=="n"], svmPred.k.prob$c, svmPredProb$c[labelTest$label=="c"])))
str(predicted.c)
boxplot(prob ~ label, data = as.data.frame(predicted.c), main = "Samples (by label) predicted as OSCC", ylab = "Probability", outpch = NA)
stripchart(prob ~ label, data = as.data.frame(predicted.c),
vertical = TRUE, method = "jitter",
pch = 21, col = "maroon", bg = "bisque",
add = TRUE)
mtext ("Prediction probability")
##=============================
##	Test on olk sample
##=============================
dim(file.olk)
svmPred.k.prob  <- predict(svmTune, file.olk, type = "prob")
den.c <- density(svmPred.k.prob$c)
label.k.as.c <- svmPred.k.prob$c
den.n <- density(svmPred.k.prob$n)
length(which(svmPred.k.prob$c > 0.5))
length(which(svmPred.k.prob$n > 0.5))
plot( den.c)
lines( den.n, col = "red")
file.olk[-which(svmPred.k.prob$c >0.5),]
plot(density(svmPred.k.prob$c))
plot(density(svmPred.k.prob$n))
pairs(svmPred.k.prob)
##==============================
##	To get the figure 6
##==============================
rep ("c", length(label.c.as.c))
rep ("n", length(label.n.as.c))
rep ("k", length(label.k.as.c))
predicted.c <- list (label = as.vector(c(rep ("n", length(label.n.as.c)), rep ("k", length(label.k.as.c)), rep ("c", length(label.c.as.c)))),
prob = as.vector(c( svmPredProb$c[labelTest$label=="n"], svmPred.k.prob$c, svmPredProb$c[labelTest$label=="c"])))
str(predicted.c)
boxplot(prob ~ label, data = as.data.frame(predicted.c), main = "Samples (by label) predicted as OSCC", ylab = "Probability", outpch = NA)
stripchart(prob ~ label, data = as.data.frame(predicted.c),
vertical = TRUE, method = "jitter",
pch = 21, col = "maroon", bg = "bisque",
add = TRUE)
