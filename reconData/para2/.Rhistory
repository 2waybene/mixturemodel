third_round
index
if (index >=1)
{
secondDT.1 <- getPopWIndex (secondDT.cleaned, index)
#plot(density(secondDT.1))
#plot(density(secondDT.1 + peaks[index]))
secondDT.2.cleaned <- cleanFirstPop(peaks[index],  secondDT.1, secondDT.cleaned)
third_round = 1
#str(secondDT.2.cleaned)
#plot(density(secondDT.2.cleaned))
#stats (secondDT.2.cleaned)
}else{
secondDT.2.cleaned <- secondDT.cleaned
}
secondDT.2.cleaned
library(ks)
set.seed(1)
par(mfrow=c(2,1))
x<-rlnorm(100)
hist(x, col="red", freq=F)
lines(density(x))
y <- rkde(fhat=kde(x=x, h=hpi(x)), n=100, positive=TRUE)
hist(y, col="green", freq=F)
#	simulating DNA D.I. values
# Need to source ~/myGit/mixturemodel/Scripts/simDt_functions.R
#	normal population
library(Rlab)
##  OS specific directories:
mac.os  <- "/Users/li11/"
linux   <- "~/"
windows <- "X:/"
root <- mac.os
source (paste (root, "/myGit/mixturemodel/Scripts/simDt_functions.R", sep=""))
source (paste (root, "/myGit/mixturemodel/Scripts/simDt_functions.R", sep=""))
mean.norm <- c()
for (i in 1:20)
{
mean.norm[i] <- runif (1, 0.9,1.2)
}
mean.normalP <- mean.norm[sample(1:20,1)]
#	mitotic population
mean.mitotic <- c()
for (i in 1:20)
{
mean.mitotic[i] <- runif (1, 1.7,2.2)
}
mean.mitoticP <- mean.mitotic[sample(1:20,1)]
#	aneuploidy  population
mean.aneu <- 3.3
st.aneu <-3.5
n = 40
sample.aneu <- rnorm(n, mean = mean.aneu, sd = st.aneu)
sample.aneuP <- sample.aneu[sample.aneu >=0]
plot(density(sample.aneuP))
mean.aneuP <- mean(sample.aneuP)
sigmaA <- sd(sample.aneuP)
#  simulating DNA D.I. values
# Need to source ~/myGit/mixturemodel/Scripts/simDt_functions.R
#	normal population
library(Rlab)
##  OS specific directories:
mac.os  <- "/Users/li11/"
linux   <- "~/"
windows <- "X:/"
##=============================================
##  Read in data
##=============================================
#root <- windows
root <- mac.os
dt.dir <- paste (root, "/myGit/mixturemodel/cleanedData/OSCC", sep="")
files <- list.files (pattern=".rda")
files
files <- list.files (path = dt.dir, pattern=".rda")
files
i=1
load(paste(dt.dir, files[i], sep=""))
files[i]
dt.dir <- paste (root, "/myGit/mixturemodel/cleanedData/OSCC/", sep="")
files <- list.files (path = dt.dir, pattern=".rda")
files
aneuMax = 0;
aneuMin = 0;
i=1
load(paste(dt.dir, files[i], sep=""))
str()
ls()
str(cleanedSample)
str(cleanedSample$Aneuleft)
str(cleanedSample$AneuLeft)
max(cleanedSample$AneuLeft)
aneuMax = 0;
aneuMin = 2.3;
for (i in 1:length(files))
{
load(paste(dt.dir, files[i], sep=""))
if (aneuMax < max(cleanedSample$AneuLeft))
{
aneuMax = max(cleanedSample$AneuLeft))
}
}
i=1
load(paste(dt.dir, files[i], sep=""))
for (i in 1:length(files))
{
load(paste(dt.dir, files[i], sep=""))
if (aneuMax < max(cleanedSample$AneuLeft))
{
aneuMax = max(cleanedSample$AneuLeft)
}
}
for (i in 1:length(files))
{
load(paste(dt.dir, files[i], sep=""))
if (cleanedSample$AneuLeft) != "")
{
if (aneuMax < max(cleanedSample$AneuLeft))
{
aneuMax = max(cleanedSample$AneuLeft)
}
}
}
for (i in 1:length(files))
{
load(paste(dt.dir, files[i], sep=""))
if (cleanedSample$AneuLeft != "")
{
if (aneuMax < max(cleanedSample$AneuLeft))
{
aneuMax = max(cleanedSample$AneuLeft)
}
}
}
i
(cleanedSample$AneuLeft != "")
cleanedSample$AneuLeft
cleanedSample
cleanedSample$AneuLeft
length(cleanedSample$AneuLeft)
(length(cleanedSample$AneuLeft) != 0)
for (i in 1:length(files))
{
load(paste(dt.dir, files[i], sep=""))
if (length(cleanedSample$AneuLeft) != 0)
{
if (aneuMax < max(cleanedSample$AneuLeft))
{
aneuMax = max(cleanedSample$AneuLeft)
}
}
}
aneuMax
?do.call
do.call("complex", list(imag = 1:3))
library(golubEsets)
library(pvca)
data(Golub_Merge)
pct_threshold <- 0.6
batch.factors <- c("ALL.AML", "BM.PB", "Source")
pvcaObj <- pvcaBatchAssess (Golub_Merge, batch.factors, pct_threshold)
bp <- barplot(pvcaObj$dat,  xlab = "Effects",
ylab = "Weighted average proportion variance",
ylim= c(0,1.1),col = c("blue"), las=2,
main="PVCA estimation bar chart")
axis(1, at = bp, labels = pvcaObj$label, xlab = "Effects", cex.axis = 0.5, las=2)
values = pvcaObj$dat
new_values = round(values , 3)
text(bp,pvcaObj$dat,labels = new_values, pos=3, cex = 0.8)
license()
demo()
library(AppliedPredictiveModeling)
transparentTheme(trans = 0.4)
plotSubset <- data.frame(scale(mdrrDescr[, c("nC", "X4v")]))
xyplot(nC ~ X4v,
data = plotSubset,
groups = mdrrClass,
auto.key = list(columns = 2))
plot(1:5)
##==============================================
mac.os  <- "/Users/li11/"
linux   <- "~/"
windows <- "X:/"
root <- mac.os
library(caret)
##===================================
## set up working directory
## and getting the dataset
##===================================
setwd(paste (root, "/myGit/mixturemodel/reconData/para2/", sep=""))
data <- read.table("recon_3classes_para3.txt", header=TRUE, sep = "\t")
##	data cleaning
var0 <- unlist(lapply(data, function(x) 0 == var(if (is.factor(x)) as.integer(x) else x)))
dataN0 <- data[,-which(var0)]
# drop the first column of ID?
dataN0[,1] <- NULL
##	Retain data ONLY with two classes
data.2.classes <- dataN0[-which (dataN0$label == "k"),]
data.k <- dataN0[which (dataN0$label == "k"),]
dim(data.2.classes)
labels <- as.vector(data.2.classes$label)
data.2.classes <- data.2.classes[,-16]
data.2.classes <- cbind (data.2.classes, label=labels)
table(factor(data.2.classes$label))
file2classes  <- data.2.classes
file.olk <- data.k
## create data partition
inTrainingSet <- createDataPartition(file2classes$label, p=.7, list=FALSE)
labelTrain <- file2classes[ inTrainingSet,]
labelTest <- file2classes[-inTrainingSet,]
nrow(labelTrain)
nrow(labelTest)
##=======================
##	rpart
##=======================
library(rpart)
library(partykit)
rpartFull <- rpart(label ~ ., data = labelTrain)
rpartFulla <- as.party(rpartFull)
plot(rpartFulla)
rpartPred <- predict(rpartFull, labelTest, type = "class")
confusionMatrix(rpartPred, labelTest$label)   # requires 2 factor vectors
cvCtrl <- trainControl(method = "repeatedcv", repeats = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
set.seed(1)
rpartTune <- train(label ~ ., data = labelTrain,
method = "rpart",
tuneLength = 10,
metric = "ROC",
trControl = cvCtrl)
rpartPred2 <- predict(rpartTune, labelTest)
confusionMatrix(rpartPred2, labelTest$label)
##=======================
##	C5.0
##=======================
grid <- expand.grid(model = "tree",
trials = c(1:100),
winnow = FALSE)
set.seed(1)
c5Tune <- train(labelTrain, labelTrain$label,
method = "C5.0",
metric = "ROC",
tuneGrid = grid,
trControl = cvCtrl)
c5Pred <- predict(c5Tune, labelTest)
confusionMatrix(c5Pred, labelTest$label)
##====================================
##	SVM Example
##====================================
set.seed(1)
svmTune <- train(label ~ .,
data = labelTrain,
method = "svmRadial",
# The default grid of cost parameters go from 2^-2,
# 0.5 to 1,
# We'll fit 9 values in that sequence via the tuneLength
# argument.
tuneLength = 9,
preProc = c("center", "scale"),
metric = "ROC",
trControl = cvCtrl)
svmPred <- predict(svmTune, labelTest)
confusionMatrix(svmPred, labelTest$label)
##=============================
##	Test on olk sample
##=============================
dim(file.olk)
svmPred.k.prob  <- predict(svmTune, file.olk, type = "prob")
svmPred.k.prob
file.olk[-which(svmPred.k.prob$c >0.5),]
plot(density(svmPred.k.prob$c))
plot(density(svmPred.k.prob$n))
pairs(svmPred.k.prob)
###############################################################
## Slide 117: A Few Other Models
set.seed(1)
fdaTune <- train(label ~ ., data = labelTrain,
method = "fda",
tuneLength = 12,
metric = "ROC",
trControl = cvCtrl)
set.seed(1)
fdaTune <- train(label ~ ., data = labelTrain,
method = "fda",
tuneLength = 12,
metric = "ROC",
trControl = cvCtrl)
fdaPred <- predict(fdaTune, labelTest)
confusionMatrix(fdaPred, labelTest$label)
set.seed(1)
plrTune <- train(label ~ ., data = labelTrain,
method = "multinom",
preProc = c("center", "scale"),
tuneGrid = data.frame(decay = c(0.1, 1, 10, 20, 40)),
trace = FALSE, maxit = 1000,
metric = "ROC",
trControl = cvCtrl)
plrPred <- predict(plrTune, labelTest)
confusionMatrix(plrPred, labelTest$label)
library(randomForest)
RFTune <- train(label ~.,data=labelTrain,
method = "rf",
tuneLength = 12,
metric = "ROC",
trControl = cvCtrl)
RFPred2 <- predict(RFTune, labelTest)
confusionMatrix(RFPred2, labelTest$label)
RFtrain <- randomForest(label ~.,data=labelTrain )
RFPred <- predict(RFtrain, labelTest)
confusionMatrix(RFPred, labelTest$label)
rrfFit <- train(label ~ ., method = "RRF", data = labelTrain)
rrfPred <- predict(rrfFit, labelTest)
confusionMatrix(rrfPred, labelTest$label)
knnFit1 <- train(label ~.,data=labelTrain,
method = "knn",
preProcess = c("center", "scale"),
metric = "ROC",
tuneLength = 10,
trControl = cvCtrl)
knnPred <- predict(knnFit1, labelTest)
confusionMatrix(knnPred , labelTest$label)
library(MASS)
nnetFit <- train(label ~.,data=labelTrain,
method = "nnet",
preProcess = "range",
tuneLength = 2,
metric = "ROC",
trace = FALSE,
maxit = 100,
trControl = cvCtrl)
nnetPred <- predict(nnetFit, labelTest)
confusionMatrix(nnetPred , labelTest$label)
cvValues <- resamples(list(CART = rpartTune, SVM = svmTune,
C5.0 = c5Tune, FDA = fdaTune,
plr = plrTune, nnet = nnetFit,
knn = knnFit1, rrf = RFTune)
)
summary(cvValues)
trellis.par.set(caretTheme())
plot(nnetFit)
plot(knnFit1)
plot(RFTune)
plot(svmTune)
trellis.par.set()
bwplot(cvValues, layout = c(3, 1))
data <- read.table("recon_3classes_para1.txt", header=TRUE, sep = "\t")
##	data cleaning
var0 <- unlist(lapply(data, function(x) 0 == var(if (is.factor(x)) as.integer(x) else x)))
dataN0 <- data[,-which(var0)]
# drop the first column of ID?
dataN0[,1] <- NULL
##	Retain data ONLY with two classes
data.2.classes <- dataN0[-which (dataN0$label == "k"),]
data.k <- dataN0[which (dataN0$label == "k"),]
dim(data.2.classes)
labels <- as.vector(data.2.classes$label)
data.2.classes <- data.2.classes[,-16]
data.2.classes <- cbind (data.2.classes, label=labels)
table(factor(data.2.classes$label))
#levels(data.2.classes$label) <- factor (data.2.classes$label)
file2classes  <- data.2.classes
file.olk <- data.k
## create data partition
inTrainingSet <- createDataPartition(file2classes$label, p=.7, list=FALSE)
labelTrain <- file2classes[ inTrainingSet,]
labelTest <- file2classes[-inTrainingSet,]
nrow(labelTrain)
nrow(labelTest)
##=======================
##	rpart
##=======================
library(rpart)
library(partykit)
rpartFull <- rpart(label ~ ., data = labelTrain)
rpartFulla <- as.party(rpartFull)
plot(rpartFulla)
rpartPred <- predict(rpartFull, labelTest, type = "class")
confusionMatrix(rpartPred, labelTest$label)   # requires 2 factor vectors
cvCtrl <- trainControl(method = "repeatedcv", repeats = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
set.seed(1)
rpartTune <- train(label ~ ., data = labelTrain,
method = "rpart",
tuneLength = 10,
metric = "ROC",
trControl = cvCtrl)
rpartPred2 <- predict(rpartTune, labelTest)
confusionMatrix(rpartPred2, labelTest$label)
##=======================
##	C5.0
##=======================
grid <- expand.grid(model = "tree",
trials = c(1:100),
winnow = FALSE)
set.seed(1)
c5Tune <- train(labelTrain, labelTrain$label,
method = "C5.0",
metric = "ROC",
tuneGrid = grid,
trControl = cvCtrl)
c5Pred <- predict(c5Tune, labelTest)
confusionMatrix(c5Pred, labelTest$label)
##====================================
##	SVM Example
##====================================
set.seed(1)
svmTune <- train(label ~ .,
data = labelTrain,
method = "svmRadial",
# The default grid of cost parameters go from 2^-2,
# 0.5 to 1,
# We'll fit 9 values in that sequence via the tuneLength
# argument.
tuneLength = 9,
preProc = c("center", "scale"),
metric = "ROC",
trControl = cvCtrl)
svmPred <- predict(svmTune, labelTest)
confusionMatrix(svmPred, labelTest$label)
##=============================
##	Test on olk sample
##=============================
dim(file.olk)
svmPred.k.prob  <- predict(svmTune, file.olk, type = "prob")
svmPred.k.prob
file.olk[-which(svmPred.k.prob$c >0.5),]
plot(density(svmPred.k.prob$c))
plot(density(svmPred.k.prob$n))
pairs(svmPred.k.prob)
###############################################################
## Slide 117: A Few Other Models
set.seed(1)
fdaTune <- train(label ~ ., data = labelTrain,
method = "fda",
tuneLength = 12,
metric = "ROC",
trControl = cvCtrl)
fdaPred <- predict(fdaTune, labelTest)
confusionMatrix(fdaPred, labelTest$label)
set.seed(1)
plrTune <- train(label ~ ., data = labelTrain,
method = "multinom",
preProc = c("center", "scale"),
tuneGrid = data.frame(decay = c(0.1, 1, 10, 20, 40)),
trace = FALSE, maxit = 1000,
metric = "ROC",
trControl = cvCtrl)
plrPred <- predict(plrTune, labelTest)
confusionMatrix(plrPred, labelTest$label)
##========================
##	randomForest
##========================
library(randomForest)
RFTune <- train(label ~.,data=labelTrain,
method = "rf",
tuneLength = 12,
metric = "ROC",
trControl = cvCtrl)
RFPred2 <- predict(RFTune, labelTest)
confusionMatrix(RFPred2, labelTest$label)
RFtrain <- randomForest(label ~.,data=labelTrain )
RFPred <- predict(RFtrain, labelTest)
confusionMatrix(RFPred, labelTest$label)
rrfFit <- train(label ~ ., method = "RRF", data = labelTrain)
rrfPred <- predict(rrfFit, labelTest)
confusionMatrix(rrfPred, labelTest$label)
knnFit1 <- train(label ~.,data=labelTrain,
method = "knn",
preProcess = c("center", "scale"),
metric = "ROC",
tuneLength = 10,
trControl = cvCtrl)
knnPred <- predict(knnFit1, labelTest)
confusionMatrix(knnPred , labelTest$label)
library(MASS)
nnetFit <- train(label ~.,data=labelTrain,
method = "nnet",
preProcess = "range",
tuneLength = 2,
metric = "ROC",
trace = FALSE,
maxit = 100,
trControl = cvCtrl)
nnetPred <- predict(nnetFit, labelTest)
confusionMatrix(nnetPred , labelTest$label)
###############################################################
## Slide 118: Collecting Results With resamples
cvValues <- resamples(list(CART = rpartTune, SVM = svmTune,
C5.0 = c5Tune, FDA = fdaTune,
plr = plrTune, nnet = nnetFit,
knn = knnFit1, rrf = RFTune)
)
###############################################################
## Slide 119: Collecting Results With resamples
summary(cvValues)
##==========================================================
##	Learning model training with Caret
##	http://topepo.github.io/caret/training.html#control
##==========================================================
trellis.par.set(caretTheme())
plot(nnetFit)
plot(knnFit1)
plot(RFTune)
plot(svmTune)
##=================
#	box plot
##=================
trellis.par.set()
bwplot(cvValues, layout = c(3, 1))
summary(cvValues)
getwd()
