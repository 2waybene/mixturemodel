{
numOfFamily = 3
}else if (length(which(as.vector(dt$DNA_Index) > mitoThresh)) > 1)
{
numOfFamily = 2
}
numOfFamily
##===================================================
##  removing the normal family
##  upto two round
##===================================================
dt.raw  <- ""
firstDT <- ""
get.gen <- ""
peaks   <- c()
dt.raw <- as.vector (dt$DNA_Index)
tol.num.of.dt <- length(dt.raw)
get.den <- density(dt.raw)
peaks <- peak.quick (get.den$x, get.den$y)
peaks
##==========================================================
##  Determine where to start the first population
##  There could be more small peaks less than 1
##  Try to get the first one peaks > 1 but < 1.2 (normMax)
##==========================================================
index = 1
length(which(peaks < 1))
if (!(is.na((peaks[length(which(peaks<1)) + 1]))) & peaks[length(which(peaks<1)) + 1] < normMax )
{
index = length(which(peaks<1)) + 1
}else { index = length(which(peaks<1)) }
index
##============================================
##  clean starts here with first population
##============================================
firstDT <- getPopWIndex (dt.raw, index)
##  Save first population dt
FP_dt_primary <- firstDT + peaks[index]
dt.cleaned <- cleanFirstPop(peaks[index], firstDT, dt.raw)
if (length(firstDT) >= length(dt.raw) & numOfFamily <=2)
{
SP_dt_primary <- dt.raw[c(which(dt.raw > normMax))]
FP_mean  <- mean(FP_dt_primary)
FP_std   <- sd(FP_dt_primary)
FP_count <- length(FP_dt_primary)
FP <- list ("FP_mean" = FP_mean, "FP_std" = FP_std, "FP_count" = FP_count)
cleanedSample <- c(cleanedSample, FP)
}else{
##================================
##  Second round if ever needed
##================================
if (length (get.den <- tryDensity (dt.cleaned)) >=1 )
{
dt.raw  <- dt.cleaned
firstDT <- ""
get.gen <- ""
peaks   <- c()
index = 1
firstDT <- getPopWIndex (dt.raw, index) ##FIXME, yep breaks at sample 88!!!!
get.den <- density(dt.raw)
peaks <- peak.quick (get.den$x, get.den$y)
peaks
##=========================================
##  Follow the same protocol, but just
##  carry out one more cleaning cycle
##  if there is any peaks less than 1.2(normMax)
##===========================================
##Need to add the "cleaned back to population one"!!
dt.clean.return = list()
if (peaks[1] < normMax )
{
dt.clean.return <- followUpClean (peaks[1], firstDT, dt.raw)
if (length(dt.clean.return$dtFiltered) > 1) #FIXME, there was a bug
{
FP_dt_primary <- c(FP_dt_primary, dt.clean.return$dtFiltered)
}
dt.1pop.cleaned <- dt.clean.return$dtRetain
}else{
dt.1pop.cleaned <- dt.cleaned
}
##===================================
##  Storing the cleaning results
##===================================
FP_mean  <- mean(FP_dt_primary)
FP_std   <- sd(FP_dt_primary)
FP_count <- length(FP_dt_primary)
FP <- list ("FP_mean" = FP_mean, "FP_std" = FP_std, "FP_count" = FP_count)
cleanedSample <- c(cleanedSample, FP)
} else
{
FP_mean  <- mean(FP_dt_primary)
FP_std   <- sd(FP_dt_primary)
FP_count <- length(FP_dt_primary)
FP <- list ("FP_mean" = FP_mean, "FP_std" = FP_std, "FP_count" = FP_count)
cleanedSample <- c(cleanedSample, FP)
dt.1pop.cleaned <- dt.cleaned
}
}
##===========================================
##  No need to clean the second population
##===========================================
SP_mean  <- mean(SP_dt_primary)
SP_std   <- sd(SP_dt_primary)
SP_count <- length(SP_dt_primary)
SP <- list ("SP_mean" = SP_mean, "SP_std" = SP_std, "SP_count" = SP_count)
cleanedSample <- c(cleanedSample, SP)
aneup.pop <- ""
aneu <- list ("AneuLeft" = aneup.pop)
cleanedSample <- c(cleanedSample, aneu)
cleanedSample
parameters
##=====================================================
library(Rlab)
##  OS specific directories:
mac.os  <- "/Users/li11/"
linux   <- "~/"
windows <- "X:/"
#root <- windows
root <- mac.os
##==================================================================================
source (paste (root, "myGit/mixturemodel/Scripts/cleaningFuncs.R", sep = ""))
source (paste (root, "myGit/mixturemodel/Scripts/simDt_functions.R", sep = ""))
source (paste (root, "myGit/mixturemodel/Scripts/reconstrDtFunctions.R", sep = ""))
parameters <- para4()
parameters
dt.dir <- paste (root, "/myGit/mixturemodel/cleanedData/OLK/", sep="")
lab <- "k"
files <- list.files (path = dt.dir, pattern=".rda")
load(paste(dt.dir, "cleaned_9559503.rda", sep=""))
files
load(paste(dt.dir, "cleaned_9559547.rda", sep=""))
str(cleanedSample)
i
rawFiles
fileName <- paste("myGit/mixturemodel/data/dt_01232014/OLK/", rawFiles[i], sep ="")
fileName
f_IN <-  paste (root, fileName, sep ="")
nameSplit <- strsplit(f_IN, "/")[[1]]
sampleName <- nameSplit[length(nameSplit)]
sampleName <- sub(".csv", "", sampleName)
sampleName
cleanedSample <-  list("sample" = sampleName)
cleanedSample
dt <- read.csv (f_IN)
summary(dt)
## determine how many families are we dealing with
numOfFamily <-  1 # minimun one family
if (length(which(as.vector(dt$DNA_Index) > aneuThresh)) >= 1)
{
numOfFamily = 3
}else if (length(which(as.vector(dt$DNA_Index) > mitoThresh)) > 1)
{
numOfFamily = 2
}
numOfFamily
dt
head(dt)
summary(dt)
dt.raw <- as.vector (dt$DNA_Index)
tol.num.of.dt <- length(dt.raw)
tol.num.of.dt
get.den <- density(dt.raw)
peaks <- peak.quick (get.den$x, get.den$y)
peaks
plot(density(dt.raw))
is.na((peaks[length(which(peaks<1)) + 1])))
(is.na((peaks[length(which(peaks<1)) + 1]))
)
peaks[length(which(peaks<1)) + 1]
peaks[length(which(peaks<1)) + 1] < normMax
length(which(peaks<1)) + 1
index = 1
length(which(peaks < 1))
if (!(is.na((peaks[length(which(peaks<1)) + 1]))) & peaks[length(which(peaks<1)) + 1] < normMax )
{
index = length(which(peaks<1)) + 1
}else { index = length(which(peaks<1)) }
index
firstDT <- getPopWIndex (dt.raw, index)
plot(density(firstDT))
FP_dt_primary <- firstDT + peaks[index]
FP_dt_primary
peaks[index]
dt.cleaned <- cleanFirstPop(peaks[index], firstDT, dt.raw)
FP_dt_primary
plot(density(dt.cleaned))
(length (get.den <- tryDensity (dt.cleaned)) >=1 )
get.den
tryDensity (dt.cleaned)
(length (get.den <- tryDensity (dt.cleaned)) >=1 )
900*12
13000*.75
130000*.75
#===============================================
##	Set up os paths
##==============================================
mac.os  <- "/Users/li11/"
linux   <- "~/"
windows <- "X:/"
root <- mac.os
library(caret)
##===================================
## set up working directory
## and getting the dataset
##===================================
setwd(paste (root, "/myGit/mixturemodel/reconData/para2/", sep=""))
data <- read.table("recon_3classes_para3.txt", header=TRUE, sep = "\t")
#data <- read.table("recon_3classes_para1.txt", header=TRUE, sep = "\t")
#data <- read.table("recon_3classes_para2.txt", header=TRUE, sep = "\t")
##	data cleaning
var0 <- unlist(lapply(data, function(x) 0 == var(if (is.factor(x)) as.integer(x) else x)))
dataN0 <- data[,-which(var0)]
# drop the first column of ID?
dataN0[,1] <- NULL
##	Retain data ONLY with two classes
data.2.classes <- dataN0[-which (dataN0$label == "k"),]
data.k <- dataN0[which (dataN0$label == "k"),]
dim(data.2.classes)
labels <- as.vector(data.2.classes$label)
data.2.classes <- data.2.classes[,-16]
data.2.classes <- cbind (data.2.classes, label=labels)
file2classes  <- data.2.classes
## create data partition
inTrainingSet <- createDataPartition(file2classes$label, p=.7, list=FALSE)
labelTrain <- file2classes[ inTrainingSet,]
labelTest <- file2classes[-inTrainingSet,]
nrow(labelTrain)
nrow(labelTest)
##=======================
##	rpart
##=======================
library(rpart)
library(partykit)
cvCtrl <- trainControl(method = "repeatedcv", repeats = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
set.seed(1)
rpartTune <- train(label ~ ., data = labelTrain,
method = "rpart",
tuneLength = 10,
metric = "ROC",
trControl = cvCtrl)
##====================================
##	SVM Example
##====================================
#set.seed(1)
svmTune <- train(label ~ .,
data = labelTrain,
method = "svmRadial",
# The default grid of cost parameters go from 2^-2,
# 0.5 to 1,
# We'll fit 9 values in that sequence via the tuneLength
# argument.
tuneLength = 9,
preProc = c("center", "scale"),
metric = "ROC",
trControl = cvCtrl)
##======================================
##	partial logistic regression
##========================================
plrTune <- train(label ~ ., data = labelTrain,
method = "multinom",
preProc = c("center", "scale"),
tuneGrid = data.frame(decay = c(0.1, 1, 10, 20, 40)),
trace = FALSE, maxit = 1000,
metric = "ROC",
trControl = cvCtrl)
##========================
##	randomForest
##========================
library(randomForest)
RFTune <- train(label ~.,data=labelTrain,
method = "rf",
tuneLength = 12,
metric = "ROC",
trControl = cvCtrl)
##========================
##	knn
##========================
knnFit1 <- train(label ~.,data=labelTrain,
method = "knn",
preProcess = c("center", "scale"),
metric = "ROC",
tuneLength = 10,
trControl = cvCtrl)
##========================
##	neural network
##========================
library(MASS)
nnetFit <- train(label ~.,data=labelTrain,
method = "nnet",
preProcess = "range",
tuneLength = 2,
metric = "ROC",
trace = FALSE,
maxit = 100,
trControl = cvCtrl)
###############################################################
## Slide 118: Collecting Results With resamples
cvValues <- resamples(list(CART = rpartTune, SVM = svmTune,
plr = plrTune, nnet = nnetFit,
knn = knnFit1, rrf = RFTune)
)
###############################################################
## Slide 119: Collecting Results With resamples
summary(cvValues)
trellis.par.set()
bwplot(cvValues, layout = c(3, 1))
data <- read.table("recon_3classes_para2.txt", header=TRUE, sep = "\t")
##	data cleaning
var0 <- unlist(lapply(data, function(x) 0 == var(if (is.factor(x)) as.integer(x) else x)))
dataN0 <- data[,-which(var0)]
# drop the first column of ID?
dataN0[,1] <- NULL
##	Retain data ONLY with two classes
data.2.classes <- dataN0[-which (dataN0$label == "k"),]
data.k <- dataN0[which (dataN0$label == "k"),]
dim(data.2.classes)
labels <- as.vector(data.2.classes$label)
data.2.classes <- data.2.classes[,-16]
data.2.classes <- cbind (data.2.classes, label=labels)
file2classes  <- data.2.classes
## create data partition
inTrainingSet <- createDataPartition(file2classes$label, p=.7, list=FALSE)
labelTrain <- file2classes[ inTrainingSet,]
labelTest <- file2classes[-inTrainingSet,]
nrow(labelTrain)
nrow(labelTest)
##=======================
##	rpart
##=======================
library(rpart)
library(partykit)
cvCtrl <- trainControl(method = "repeatedcv", repeats = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
set.seed(1)
rpartTune <- train(label ~ ., data = labelTrain,
method = "rpart",
tuneLength = 10,
metric = "ROC",
trControl = cvCtrl)
##====================================
##	SVM Example
##====================================
#set.seed(1)
svmTune <- train(label ~ .,
data = labelTrain,
method = "svmRadial",
# The default grid of cost parameters go from 2^-2,
# 0.5 to 1,
# We'll fit 9 values in that sequence via the tuneLength
# argument.
tuneLength = 9,
preProc = c("center", "scale"),
metric = "ROC",
trControl = cvCtrl)
##======================================
##	partial logistic regression
##========================================
plrTune <- train(label ~ ., data = labelTrain,
method = "multinom",
preProc = c("center", "scale"),
tuneGrid = data.frame(decay = c(0.1, 1, 10, 20, 40)),
trace = FALSE, maxit = 1000,
metric = "ROC",
trControl = cvCtrl)
##========================
##	randomForest
##========================
library(randomForest)
RFTune <- train(label ~.,data=labelTrain,
method = "rf",
tuneLength = 12,
metric = "ROC",
trControl = cvCtrl)
##========================
##	knn
##========================
knnFit1 <- train(label ~.,data=labelTrain,
method = "knn",
preProcess = c("center", "scale"),
metric = "ROC",
tuneLength = 10,
trControl = cvCtrl)
##========================
##	neural network
##========================
library(MASS)
nnetFit <- train(label ~.,data=labelTrain,
method = "nnet",
preProcess = "range",
tuneLength = 2,
metric = "ROC",
trace = FALSE,
maxit = 100,
trControl = cvCtrl)
###############################################################
## Slide 118: Collecting Results With resamples
cvValues <- resamples(list(CART = rpartTune, SVM = svmTune,
plr = plrTune, nnet = nnetFit,
knn = knnFit1, rrf = RFTune)
)
###############################################################
## Slide 119: Collecting Results With resamples
summary(cvValues)
trellis.par.set()
bwplot(cvValues, layout = c(3, 1))
setwd(paste (root, "/myGit/mixturemodel/reconData/para2/", sep=""))
data <- read.table("recon_3classes_para3.txt", header=TRUE, sep = "\t")
#data <- read.table("recon_3classes_para1.txt", header=TRUE, sep = "\t")
#data <- read.table("recon_3classes_para2.txt", header=TRUE, sep = "\t")
##	data cleaning
var0 <- unlist(lapply(data, function(x) 0 == var(if (is.factor(x)) as.integer(x) else x)))
dataN0 <- data[,-which(var0)]
# drop the first column of ID?
dataN0[,1] <- NULL
##	Retain data ONLY with two classes
data.2.classes <- dataN0[-which (dataN0$label == "k"),]
data.k <- dataN0[which (dataN0$label == "k"),]
dim(data.2.classes)
labels <- as.vector(data.2.classes$label)
data.2.classes <- data.2.classes[,-16]
data.2.classes <- cbind (data.2.classes, label=labels)
file2classes  <- data.2.classes
## create data partition
set.seed(1)
inTrainingSet <- createDataPartition(file2classes$label, p=.7, list=FALSE)
labelTrain <- file2classes[ inTrainingSet,]
labelTest <- file2classes[-inTrainingSet,]
nrow(labelTrain)
nrow(labelTest)
##=======================
##	rpart
##=======================
library(rpart)
library(partykit)
cvCtrl <- trainControl(method = "repeatedcv", repeats = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)
set.seed(1)
rpartTune <- train(label ~ ., data = labelTrain,
method = "rpart",
tuneLength = 10,
metric = "ROC",
trControl = cvCtrl)
##====================================
##	SVM Example
##====================================
set.seed(1)
svmTune <- train(label ~ .,
data = labelTrain,
method = "svmRadial",
# The default grid of cost parameters go from 2^-2,
# 0.5 to 1,
# We'll fit 9 values in that sequence via the tuneLength
# argument.
tuneLength = 9,
preProc = c("center", "scale"),
metric = "ROC",
trControl = cvCtrl)
##======================================
##	partial logistic regression
##========================================
plrTune <- train(label ~ ., data = labelTrain,
method = "multinom",
preProc = c("center", "scale"),
tuneGrid = data.frame(decay = c(0.1, 1, 10, 20, 40)),
trace = FALSE, maxit = 1000,
metric = "ROC",
trControl = cvCtrl)
##========================
##	randomForest
##========================
library(randomForest)
RFTune <- train(label ~.,data=labelTrain,
method = "rf",
tuneLength = 12,
metric = "ROC",
trControl = cvCtrl)
##========================
##	knn
##========================
knnFit1 <- train(label ~.,data=labelTrain,
method = "knn",
preProcess = c("center", "scale"),
metric = "ROC",
tuneLength = 10,
trControl = cvCtrl)
##========================
##	neural network
##========================
library(MASS)
nnetFit <- train(label ~.,data=labelTrain,
method = "nnet",
preProcess = "range",
tuneLength = 2,
metric = "ROC",
trace = FALSE,
maxit = 100,
trControl = cvCtrl)
###############################################################
## Slide 118: Collecting Results With resamples
cvValues <- resamples(list(CART = rpartTune, SVM = svmTune,
plr = plrTune, nnet = nnetFit,
knn = knnFit1, rrf = RFTune)
)
###############################################################
## Slide 119: Collecting Results With resamples
summary(cvValues)
trellis.par.set()
bwplot(cvValues, layout = c(3, 1))
